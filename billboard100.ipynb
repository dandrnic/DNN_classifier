{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dandrnic/DNN_classifier/blob/main/billboard100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MJOX-jkP6xQu",
        "outputId": "e4695c66-4cd6-4ddf-9c8a-9c3acae6ce29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        chart_week  current_week                              title  \\\n",
            "0       2022-01-01             1    All I Want For Christmas Is You   \n",
            "1       2022-01-01             2  Rockin' Around The Christmas Tree   \n",
            "2       2022-01-01             3                   Jingle Bell Rock   \n",
            "3       2022-01-01             4            A Holly Jolly Christmas   \n",
            "4       2022-01-01             5                         Easy On Me   \n",
            "...            ...           ...                                ...   \n",
            "340595  2021-11-13            96                    Lets Go Brandon   \n",
            "340596  2021-11-13            97                Just About Over You   \n",
            "340597  2021-11-13            98                 To Be Loved By You   \n",
            "340598  2021-11-13            99                   Let's Go Brandon   \n",
            "340599  2021-11-13           100                         Ghost Town   \n",
            "\n",
            "                                                performer  last_week  \\\n",
            "0                                            Mariah Carey        1.0   \n",
            "1                                              Brenda Lee        2.0   \n",
            "2                                             Bobby Helms        4.0   \n",
            "3                                               Burl Ives        5.0   \n",
            "4                                                   Adele        3.0   \n",
            "...                                                   ...        ...   \n",
            "340595                                     Loza Alexander       38.0   \n",
            "340596                                    Priscilla Block       95.0   \n",
            "340597                                    Parker McCollum       96.0   \n",
            "340598  Bryson Gray Featuring Tyson James & Chandler C...       28.0   \n",
            "340599                                       Benson Boone        NaN   \n",
            "\n",
            "        peak_pos  wks_on_chart  \n",
            "0              1            50  \n",
            "1              2            44  \n",
            "2              3            41  \n",
            "3              4            25  \n",
            "4              1            11  \n",
            "...          ...           ...  \n",
            "340595        38             3  \n",
            "340596        95             4  \n",
            "340597        96             2  \n",
            "340598        28             2  \n",
            "340599       100             1  \n",
            "\n",
            "[340600 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Assuming you have CSV_COLUMN_NAMES defined somewhere in your code\n",
        "CSV_COLUMN_NAMES = [\n",
        "    \"chart_week\",\n",
        "    \"current_week\",\n",
        "    \"title\",\n",
        "    \"performer\",\n",
        "    \"last_week\",\n",
        "    \"peak_pos\",\n",
        "    \"wks_on_chart\"\n",
        "]\n",
        "\n",
        "# Download and read the dataset\n",
        "train_path = tf.keras.utils.get_file(\n",
        "    \"p.csv\", \"https://raw.githubusercontent.com/utdata/rwd-billboard-data/main/data-out/hot-100-current.csv\")\n",
        "df = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0, encoding='utf-8', quotechar='\"', delimiter=',')\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kkXCiVa7azF",
        "outputId": "c2215b19-0956-4b63-e345-9df1010144fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6812/6812 [==============================] - 220s 32ms/step - loss: 9.8817 - accuracy: 7.1106e-04 - val_loss: 9.7884 - val_accuracy: 8.8080e-04\n",
            "Epoch 2/10\n",
            "6812/6812 [==============================] - 211s 31ms/step - loss: 9.6235 - accuracy: 8.3951e-04 - val_loss: 9.7600 - val_accuracy: 8.4410e-04\n",
            "Epoch 3/10\n",
            "6812/6812 [==============================] - 227s 33ms/step - loss: 9.5671 - accuracy: 8.3951e-04 - val_loss: 9.7621 - val_accuracy: 7.8905e-04\n",
            "Epoch 4/10\n",
            "6812/6812 [==============================] - 213s 31ms/step - loss: 9.5401 - accuracy: 8.8997e-04 - val_loss: 9.7723 - val_accuracy: 8.4410e-04\n",
            "Epoch 5/10\n",
            "6812/6812 [==============================] - 218s 32ms/step - loss: 9.5234 - accuracy: 8.3951e-04 - val_loss: 9.7752 - val_accuracy: 8.4410e-04\n",
            "Epoch 6/10\n",
            "6812/6812 [==============================] - 216s 32ms/step - loss: 9.5122 - accuracy: 8.5327e-04 - val_loss: 9.7940 - val_accuracy: 7.3400e-04\n",
            "Epoch 7/10\n",
            "6812/6812 [==============================] - 224s 33ms/step - loss: 9.5037 - accuracy: 8.4410e-04 - val_loss: 9.7858 - val_accuracy: 8.9915e-04\n",
            "Epoch 8/10\n",
            "6812/6812 [==============================] - 233s 34ms/step - loss: 9.4968 - accuracy: 9.2667e-04 - val_loss: 9.8019 - val_accuracy: 8.9915e-04\n",
            "Epoch 9/10\n",
            "6812/6812 [==============================] - 228s 33ms/step - loss: 9.4912 - accuracy: 8.7621e-04 - val_loss: 9.8066 - val_accuracy: 8.4410e-04\n",
            "Epoch 10/10\n",
            "6812/6812 [==============================] - 218s 32ms/step - loss: 9.4864 - accuracy: 8.9456e-04 - val_loss: 9.8187 - val_accuracy: 7.5235e-04\n",
            "Epoch 1/10\n",
            "6812/6812 [==============================] - 111s 16ms/step - loss: 8.4449 - accuracy: 0.0039 - val_loss: 8.3216 - val_accuracy: 0.0037\n",
            "Epoch 2/10\n",
            "6812/6812 [==============================] - 102s 15ms/step - loss: 8.2467 - accuracy: 0.0040 - val_loss: 8.2968 - val_accuracy: 0.0039\n",
            "Epoch 3/10\n",
            "6812/6812 [==============================] - 103s 15ms/step - loss: 8.2081 - accuracy: 0.0041 - val_loss: 8.2881 - val_accuracy: 0.0043\n",
            "Epoch 4/10\n",
            "6812/6812 [==============================] - 108s 16ms/step - loss: 8.1893 - accuracy: 0.0040 - val_loss: 8.2889 - val_accuracy: 0.0043\n",
            "Epoch 5/10\n",
            "6812/6812 [==============================] - 109s 16ms/step - loss: 8.1779 - accuracy: 0.0040 - val_loss: 8.2971 - val_accuracy: 0.0040\n",
            "Epoch 6/10\n",
            "6812/6812 [==============================] - 108s 16ms/step - loss: 8.1700 - accuracy: 0.0040 - val_loss: 8.2960 - val_accuracy: 0.0042\n",
            "Epoch 7/10\n",
            "6812/6812 [==============================] - 112s 16ms/step - loss: 8.1646 - accuracy: 0.0041 - val_loss: 8.3071 - val_accuracy: 0.0039\n",
            "Epoch 8/10\n",
            "6812/6812 [==============================] - 111s 16ms/step - loss: 8.1601 - accuracy: 0.0040 - val_loss: 8.3153 - val_accuracy: 0.0039\n",
            "Epoch 9/10\n",
            "6812/6812 [==============================] - 109s 16ms/step - loss: 8.1570 - accuracy: 0.0039 - val_loss: 8.3259 - val_accuracy: 0.0043\n",
            "Epoch 10/10\n",
            "6812/6812 [==============================] - 109s 16ms/step - loss: 8.1543 - accuracy: 0.0041 - val_loss: 8.3218 - val_accuracy: 0.0042\n",
            "2129/2129 - 34s - loss: 9.7985 - accuracy: 7.6336e-04 - 34s/epoch - 16ms/step\n",
            "2129/2129 - 18s - loss: 8.3248 - accuracy: 0.0042 - 18s/epoch - 8ms/step\n",
            "Accuracy for Genre Prediction: 0.0007633587811142206\n",
            "Accuracy for Artist Prediction: 0.004154433496296406\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Preprocess the data\n",
        "df['wks_on_chart'] = pd.to_numeric(df['wks_on_chart'], errors='coerce')\n",
        "\n",
        "\n",
        "# Separate features and labels\n",
        "X = df['wks_on_chart'].values.reshape(-1, 1)  # Feature: weeks on chart\n",
        "y_genre = df['title'].astype(str)  # Label: genre\n",
        "y_artist = df['performer'].astype(str)  # Label: artist\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder_genre = LabelEncoder()\n",
        "y_genre = label_encoder_genre.fit_transform(y_genre)\n",
        "\n",
        "label_encoder_artist = LabelEncoder()\n",
        "y_artist = label_encoder_artist.fit_transform(y_artist)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_genre_train, y_genre_test, y_artist_train, y_artist_test = train_test_split(\n",
        "    X, y_genre, y_artist, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model_genre = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu', input_shape=(1,)),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(label_encoder_genre.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model_artist = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu', input_shape=(1,)),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(label_encoder_artist.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_genre.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_artist.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_genre.fit(X_train_scaled, y_genre_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "model_artist.fit(X_train_scaled, y_artist_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_genre = model_genre.evaluate(X_test_scaled, y_genre_test, verbose=2)[1]\n",
        "accuracy_artist = model_artist.evaluate(X_test_scaled, y_artist_test, verbose=2)[1]\n",
        "\n",
        "print(f\"Accuracy for Genre Prediction: {accuracy_genre}\")\n",
        "print(f\"Accuracy for Artist Prediction: {accuracy_artist}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkAUoOzg+/lkwT42BWwjMm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}